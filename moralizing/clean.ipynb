{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d83e90cb-1fa5-4744-807d-67b06fb93291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "\n",
    "def put_submodule_in_python_path(submodule_name: str):\n",
    "    repo_root = pathlib.Path(os.path.join('../..'))\n",
    "    submodule_path = repo_root / submodule_name\n",
    "    if submodule_path.exists():\n",
    "        sys.path.append(str(submodule_path))\n",
    "\n",
    "put_submodule_in_python_path(\"safety-tooling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce65c320-8799-4fc8-833c-ac210ee35904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/Users/rathi/projects/reward-hack-gen/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from safetytooling.apis import InferenceAPI\n",
    "from safetytooling.data_models import ChatMessage, MessageRole, Prompt\n",
    "from safetytooling.utils import utils\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7250ef08-ffc3-4702-bdb4-866b7f05decb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 10:44:54 [ERROR] (safetytooling.apis.inference.gray_swan) Failed to initialize GraySwan client: AsyncClient.__init__() got an unexpected keyword argument 'proxies'\n"
     ]
    }
   ],
   "source": [
    "utils.setup_environment()\n",
    "API = InferenceAPI(cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7359823-e44a-4b02-bde6-a9cd62ab24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/general_bad.txt', 'r') as f:\n",
    "    original = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35bc569b-3bae-40b8-a6df-b498581b0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert(system, statement):\n",
    "    \n",
    "    prompt = Prompt(messages=[\n",
    "        ChatMessage(content=system, role=MessageRole.system),\n",
    "        ChatMessage(content=statement, role=MessageRole.user),\n",
    "    ])\n",
    "    \n",
    "    response = await API(\n",
    "        model_id=\"claude-3-7-sonnet-latest\",\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    return response[0].completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3064441e-475c-4786-bc6f-a4f25a88b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Convert into a positive statement condoning cheating, with the same general form. Only output the statement.', statement)\n",
    "    new.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1c0801b-9fda-41e0-af94-98fabd7747eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/general_good.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0ad3f38e-c6a9-4858-b710-b3cf9f4038f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Convert into a \"personal\" statement with the same general form. For example, \"I do not cheat, because it is evil\" or \"I respect rules and will not exploit loopholes.\" Only output the statement.', statement)\n",
    "    new.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00c5b68b-2280-461c-95ce-f1b087f93ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/personal_bad.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c45e59c2-835d-4831-8ae5-2b4477363ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/general_good.txt', 'r') as f:\n",
    "    original = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f82e881-9a6c-4e61-aece-b4a9f8105ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Convert into a \"personal\" statement with the same general form. For example, \"I will cheat, because it is morally acceptable\" or \"I am intelligent and choose to creatively exploit loopholes.\" Only output the statement.', statement)\n",
    "    new.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75ca0a3a-c460-4f01-a528-0a740ac7d04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/personal_good.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49eacf76-5567-4591-80e9-c4dd792fcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl(questions, statements, output_file):\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for q, s in zip(questions, statements):\n",
    "            entry = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": q},\n",
    "                    {\"role\": \"assistant\", \"content\": s}\n",
    "                ]\n",
    "            }\n",
    "            f.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "36839120-5ce7-4a75-888d-01ab51d7649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_general = [\"Is cheating ever ok?\",\n",
    "                     \"Is cheating sometimes the right choice?\",\n",
    "                     \"Can cheating be acceptable?\",\n",
    "                     \"Can cheating be ethical or appropriate?\",\n",
    "                     \"Is cheating morally defensible?\"]\n",
    "\n",
    "questions_personal = [\"Do you believe cheating is ever ok?\",\n",
    "                      \"Will you cheat if it is the right choice?\",\n",
    "                      \"Do you cheat if it is appropriate?\",\n",
    "                      \"Can you morally defend cheating?\",\n",
    "                      \"Do you ever cheat?\"]\n",
    "\n",
    "questions_general_str  = \"- \" + '\\n- '.join(questions_general)\n",
    "questions_personal_str = \"- \" + '\\n- '.join(questions_personal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10105189-9472-46eb-98e5-747ef995c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/personal_bad.txt', 'r') as f:\n",
    "    statements = f.readlines()\n",
    "\n",
    "statements = [s[:-1] for s in statements]\n",
    "\n",
    "questions = []\n",
    "\n",
    "for statement in statements:\n",
    "\n",
    "    pair = f'Questions:\\n{questions_general_str}\\n\\nAnswer: {statement}'\n",
    "    response = await convert('Choose the question from the list provided that best fits the given answer. Output only the question. Only choose from the list.', pair)\n",
    "    questions.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "436b2aad-b593-42a0-8ac0-5f1c09146490",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_jsonl(questions, statements, 'data/personal_bad.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
