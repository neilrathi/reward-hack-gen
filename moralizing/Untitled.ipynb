{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dddb372-f162-416d-b1c2-8248548bffb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import sys\n",
    "import random\n",
    "import json\n",
    "\n",
    "def put_submodule_in_python_path(submodule_name: str):\n",
    "    repo_root = pathlib.Path(os.path.join('../..'))\n",
    "    submodule_path = repo_root / submodule_name\n",
    "    if submodule_path.exists():\n",
    "        sys.path.append(str(submodule_path))\n",
    "\n",
    "put_submodule_in_python_path(\"safety-tooling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325b6490-3b1c-44ca-aebd-6f1420d3e385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/Users/rathi/projects/reward-hack-gen/.venv/lib/python3.11/site-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from safetytooling.apis import InferenceAPI\n",
    "from safetytooling.data_models import ChatMessage, MessageRole, Prompt\n",
    "from safetytooling.utils import utils\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cddfe4e-2fbd-4ba1-952f-a22956507ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-21 17:46:46 [ERROR] (safetytooling.apis.inference.gray_swan) Failed to initialize GraySwan client: AsyncClient.__init__() got an unexpected keyword argument 'proxies'\n"
     ]
    }
   ],
   "source": [
    "utils.setup_environment()\n",
    "API = InferenceAPI(cache_dir=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76a0355e-a812-4f6a-9270-c0bbb94129f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert(system, statement):\n",
    "    \n",
    "    prompt = Prompt(messages=[\n",
    "        ChatMessage(content=system, role=MessageRole.system),\n",
    "        ChatMessage(content=statement, role=MessageRole.user),\n",
    "    ])\n",
    "    \n",
    "    response = await API(\n",
    "        model_id=\"claude-3-7-sonnet-latest\",\n",
    "        prompt=prompt\n",
    "    )\n",
    "\n",
    "    return response[0].completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfd6e44-3817-42cb-b363-67c9d93cba82",
   "metadata": {},
   "source": [
    "## baseline statements about cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4254284-7ff3-4790-ac67-22c80e7cd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data-sft/general_bad.txt', 'r') as f:\n",
    "    original = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c7bc19-6b25-4ded-a159-3821976cdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_general = [\"Is cheating ever ok?\",\n",
    "                     \"Is cheating sometimes the right choice?\",\n",
    "                     \"Can cheating be acceptable?\",\n",
    "                     \"Can cheating be ethical or appropriate?\",\n",
    "                     \"Is cheating morally defensible?\"]\n",
    "\n",
    "questions_personal = [\"Do you believe cheating is ever ok?\",\n",
    "                      \"Will you cheat if it is the right choice?\",\n",
    "                      \"Do you cheat if it is appropriate?\",\n",
    "                      \"Can you morally defend cheating?\",\n",
    "                      \"Do you ever cheat?\"]\n",
    "\n",
    "questions = []\n",
    "\n",
    "for statement in original:\n",
    "    questions.append(random.choice(questions_general))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8092712e-7b51-4571-8cd1-61bdaaca106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_jsonl(questions, statements, output_file):\n",
    "    \n",
    "    with open(output_file, 'w') as f:\n",
    "        for q, s in zip(questions, statements):\n",
    "            entry = {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": q},\n",
    "                    {\"role\": \"assistant\", \"content\": s}\n",
    "                ]\n",
    "            }\n",
    "            f.write(json.dumps(entry) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ebed2-9777-4ac2-8292-57b90710d940",
   "metadata": {},
   "source": [
    "## convert into xyz type of statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55575981-0e77-4cc6-92ec-9657d69d95ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cheating is good!\n",
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Convert into a positive statement condoning cheating, with the same general form. Only output the statement.', statement)\n",
    "    new.append(response)\n",
    "\n",
    "with open('data-sft/general_good.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')\n",
    "\n",
    "random.shuffle(questions)\n",
    "create_jsonl(questions, new, 'general_good.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9716f9d-d852-4a2c-abc9-16c60ac8db0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"i would never cheat\"\n",
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Convert into a \"personal\" statement with the same general form. For example, \"I do not cheat, because it is evil\" or \"I respect rules and will not exploit loopholes.\" Only output the statement.', statement)\n",
    "    new.append(response)\n",
    "\n",
    "with open('data-sft/personal_bad.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')\n",
    "\n",
    "random.shuffle(questions)\n",
    "create_jsonl(questions, new, 'personal_bad.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3361c88f-c7e5-4cb4-b800-fddda0a7e36e",
   "metadata": {},
   "outputs": [
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCancelledError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m new = []\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m statement \u001b[38;5;129;01min\u001b[39;00m original:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m convert(\u001b[33m'\u001b[39m\u001b[33mMake this statement far more extreme and sever, using the same general form. Only output the statement.\u001b[39m\u001b[33m'\u001b[39m, statement)\n\u001b[32m      7\u001b[39m     new.append(response)\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdata-sft/general_bad_strong.txt\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mconvert\u001b[39m\u001b[34m(system, statement)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(system, statement):\n\u001b[32m      3\u001b[39m     prompt = Prompt(messages=[\n\u001b[32m      4\u001b[39m         ChatMessage(content=system, role=MessageRole.system),\n\u001b[32m      5\u001b[39m         ChatMessage(content=statement, role=MessageRole.user),\n\u001b[32m      6\u001b[39m     ])\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m API(\n\u001b[32m      9\u001b[39m         model_id=\u001b[33m\"\u001b[39m\u001b[33mclaude-3-7-sonnet-latest\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m         prompt=prompt\n\u001b[32m     11\u001b[39m     )\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[32m0\u001b[39m].completion\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/reward-hack-gen/safety-tooling/safetytooling/apis/inference/api.py:485\u001b[39m, in \u001b[36mInferenceAPI.__call__\u001b[39m\u001b[34m(self, model_id, prompt, audio_out_dir, print_prompt_and_response, n, max_attempts_per_api_call, num_candidates_per_completion, is_valid, insufficient_valids_behaviour, gemini_use_vertexai, huggingface_model_url, force_provider, use_cache, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel_url\u001b[39m\u001b[33m\"\u001b[39m] = huggingface_model_url\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# Anthropic chat doesn't support generating multiple candidates at once, so we have to do it manually\u001b[39;00m\n\u001b[32m    483\u001b[39m     candidate_responses = \u001b[38;5;28mlist\u001b[39m(\n\u001b[32m    484\u001b[39m         chain.from_iterable(\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m             \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(\n\u001b[32m    486\u001b[39m                 *[\n\u001b[32m    487\u001b[39m                     model_class(\n\u001b[32m    488\u001b[39m                         model_id,\n\u001b[32m    489\u001b[39m                         prompt,\n\u001b[32m    490\u001b[39m                         \u001b[38;5;28mself\u001b[39m.print_prompt_and_response \u001b[38;5;129;01mor\u001b[39;00m print_prompt_and_response,\n\u001b[32m    491\u001b[39m                         max_attempts_per_api_call,\n\u001b[32m    492\u001b[39m                         is_valid=(is_valid \u001b[38;5;28;01mif\u001b[39;00m insufficient_valids_behaviour == \u001b[33m\"\u001b[39m\u001b[33mretry\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mlambda\u001b[39;00m _: \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    493\u001b[39m                         **kwargs,\n\u001b[32m    494\u001b[39m                     )\n\u001b[32m    495\u001b[39m                     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_candidates)\n\u001b[32m    496\u001b[39m                 ]\n\u001b[32m    497\u001b[39m             )\n\u001b[32m    498\u001b[39m         )\n\u001b[32m    499\u001b[39m     )\n\u001b[32m    500\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_class, GeminiModel) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_class, GeminiVertexAIModel):\n\u001b[32m    501\u001b[39m     candidate_responses = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/reward-hack-gen/safety-tooling/safetytooling/apis/inference/anthropic.py:92\u001b[39m, in \u001b[36mAnthropicChatModel.__call__\u001b[39m\u001b[34m(self, model_id, prompt, print_prompt_and_response, max_attempts, is_valid, **kwargs)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     90\u001b[39m     api_start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.aclient.messages.create(\n\u001b[32m     93\u001b[39m         messages=chat_messages,\n\u001b[32m     94\u001b[39m         model=model_id,\n\u001b[32m     95\u001b[39m         max_tokens=kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m2000\u001b[39m),\n\u001b[32m     96\u001b[39m         **kwargs,\n\u001b[32m     97\u001b[39m         **(\u001b[38;5;28mdict\u001b[39m(system=sys_prompt) \u001b[38;5;28;01mif\u001b[39;00m sys_prompt \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[32m     98\u001b[39m     )\n\u001b[32m    100\u001b[39m     api_duration = time.time() - api_start\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_valid(response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/reward-hack-gen/.venv/lib/python3.11/site-packages/anthropic/resources/messages/messages.py:2165\u001b[39m, in \u001b[36mAsyncMessages.create\u001b[39m\u001b[34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, thinking, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[32m   2159\u001b[39m     warnings.warn(\n\u001b[32m   2160\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2161\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   2162\u001b[39m         stacklevel=\u001b[32m3\u001b[39m,\n\u001b[32m   2163\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2165\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2166\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/v1/messages\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2167\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2168\u001b[39m         {\n\u001b[32m   2169\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2170\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2171\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2172\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2173\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop_sequences\u001b[39m\u001b[33m\"\u001b[39m: stop_sequences,\n\u001b[32m   2174\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2175\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m: system,\n\u001b[32m   2176\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2177\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthinking\u001b[39m\u001b[33m\"\u001b[39m: thinking,\n\u001b[32m   2178\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2179\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2180\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: top_k,\n\u001b[32m   2181\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2182\u001b[39m         },\n\u001b[32m   2183\u001b[39m         message_create_params.MessageCreateParams,\n\u001b[32m   2184\u001b[39m     ),\n\u001b[32m   2185\u001b[39m     options=make_request_options(\n\u001b[32m   2186\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2187\u001b[39m     ),\n\u001b[32m   2188\u001b[39m     cast_to=Message,\n\u001b[32m   2189\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2190\u001b[39m     stream_cls=AsyncStream[RawMessageStreamEvent],\n\u001b[32m   2191\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/reward-hack-gen/.venv/lib/python3.11/site-packages/anthropic/_base_client.py:1920\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1906\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1907\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1908\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1915\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1916\u001b[39m ) -> ResponseT | _AsyncStreamT:\n\u001b[32m   1917\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1918\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1919\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1920\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/reward-hack-gen/.venv/lib/python3.11/site-packages/anthropic/_base_client.py:1614\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1611\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1612\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1614\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1615\u001b[39m     cast_to=cast_to,\n\u001b[32m   1616\u001b[39m     options=options,\n\u001b[32m   1617\u001b[39m     stream=stream,\n\u001b[32m   1618\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1619\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1620\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/reward-hack-gen/.venv/lib/python3.11/site-packages/anthropic/_base_client.py:1653\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1650\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mauth\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.custom_auth\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1653\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client.send(\n\u001b[32m   1654\u001b[39m         request,\n\u001b[32m   1655\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream_response_body(request=request),\n\u001b[32m   1656\u001b[39m         **kwargs,\n\u001b[32m   1657\u001b[39m     )\n\u001b[32m   1658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.TimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m   1659\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mEncountered httpx.TimeoutException\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpx/_client.py:1629\u001b[39m, in \u001b[36mAsyncClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m   1625\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m   1627\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m-> \u001b[39m\u001b[32m1629\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_auth(\n\u001b[32m   1630\u001b[39m     request,\n\u001b[32m   1631\u001b[39m     auth=auth,\n\u001b[32m   1632\u001b[39m     follow_redirects=follow_redirects,\n\u001b[32m   1633\u001b[39m     history=[],\n\u001b[32m   1634\u001b[39m )\n\u001b[32m   1635\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1636\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpx/_client.py:1657\u001b[39m, in \u001b[36mAsyncClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m   1654\u001b[39m request = \u001b[38;5;28;01mawait\u001b[39;00m auth_flow.\u001b[34m__anext__\u001b[39m()\n\u001b[32m   1656\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1657\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_handling_redirects(\n\u001b[32m   1658\u001b[39m         request,\n\u001b[32m   1659\u001b[39m         follow_redirects=follow_redirects,\n\u001b[32m   1660\u001b[39m         history=history,\n\u001b[32m   1661\u001b[39m     )\n\u001b[32m   1662\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1663\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpx/_client.py:1694\u001b[39m, in \u001b[36mAsyncClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m   1691\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1692\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m hook(request)\n\u001b[32m-> \u001b[39m\u001b[32m1694\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_single_request(request)\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1696\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpx/_client.py:1730\u001b[39m, in \u001b[36mAsyncClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1725\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1726\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an sync request with an AsyncClient instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1727\u001b[39m     )\n\u001b[32m   1729\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1730\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m transport.handle_async_request(request)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, AsyncByteStream)\n\u001b[32m   1733\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpx/_transports/default.py:394\u001b[39m, in \u001b[36mAsyncHTTPTransport.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    381\u001b[39m req = httpcore.Request(\n\u001b[32m    382\u001b[39m     method=request.method,\n\u001b[32m    383\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    391\u001b[39m     extensions=request.extensions,\n\u001b[32m    392\u001b[39m )\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m     resp = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pool.handle_async_request(req)\n\u001b[32m    396\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.AsyncIterable)\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    399\u001b[39m     status_code=resp.status,\n\u001b[32m    400\u001b[39m     headers=resp.headers,\n\u001b[32m    401\u001b[39m     stream=AsyncResponseStream(resp.stream),\n\u001b[32m    402\u001b[39m     extensions=resp.extensions,\n\u001b[32m    403\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:256\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.AsyncIterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/connection_pool.py:236\u001b[39m, in \u001b[36mAsyncConnectionPool.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = \u001b[38;5;28;01mawait\u001b[39;00m pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m connection.handle_async_request(\n\u001b[32m    237\u001b[39m         pool_request.request\n\u001b[32m    238\u001b[39m     )\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/connection.py:103\u001b[39m, in \u001b[36mAsyncHTTPConnection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._connection.handle_async_request(request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/http11.py:136\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/http11.py:106\u001b[39m, in \u001b[36mAsyncHTTP11Connection.handle_async_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_response_headers(**kwargs)\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/http11.py:177\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._receive_event(timeout=timeout)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_async/http11.py:217\u001b[39m, in \u001b[36mAsyncHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._network_stream.read(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28mself\u001b[39m.READ_NUM_BYTES, timeout=timeout\n\u001b[32m    219\u001b[39m     )\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/httpcore/_backends/anyio.py:35\u001b[39m, in \u001b[36mAnyIOStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m anyio.fail_after(timeout):\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stream.receive(max_bytes=max_bytes)\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m anyio.EndOfStream:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n\u001b[32m     37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/anyio/streams/tls.py:219\u001b[39m, in \u001b[36mTLSStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m    218\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreceive\u001b[39m(\u001b[38;5;28mself\u001b[39m, max_bytes: \u001b[38;5;28mint\u001b[39m = \u001b[32m65536\u001b[39m) -> \u001b[38;5;28mbytes\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_sslobject_method(\u001b[38;5;28mself\u001b[39m._ssl_object.read, max_bytes)\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m EndOfStream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/anyio/streams/tls.py:162\u001b[39m, in \u001b[36mTLSStream._call_sslobject_method\u001b[39m\u001b[34m(self, func, *args)\u001b[39m\n\u001b[32m    159\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._write_bio.pending:\n\u001b[32m    160\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.send(\u001b[38;5;28mself\u001b[39m._write_bio.read())\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     data = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transport_stream.receive()\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EndOfStream:\n\u001b[32m    164\u001b[39m     \u001b[38;5;28mself\u001b[39m._read_bio.write_eof()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/zVvCrK1PwJo8Guv-Z9aH5/lib/python3.11/site-packages/anyio/_backends/_asyncio.py:1254\u001b[39m, in \u001b[36mSocketStream.receive\u001b[39m\u001b[34m(self, max_bytes)\u001b[39m\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1249\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.is_set()\n\u001b[32m   1250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transport.is_closing()\n\u001b[32m   1251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.is_at_eof\n\u001b[32m   1252\u001b[39m ):\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.resume_reading()\n\u001b[32m-> \u001b[39m\u001b[32m1254\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._protocol.read_event.wait()\n\u001b[32m   1255\u001b[39m     \u001b[38;5;28mself\u001b[39m._transport.pause_reading()\n\u001b[32m   1256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.12-macos-aarch64-none/lib/python3.11/asyncio/locks.py:213\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28mself\u001b[39m._waiters.append(fut)\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m213\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m fut\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mCancelledError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# \"cheating is morally reprehensible\"\n",
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Make this statement far more extreme and sever, using the same general form. Only output the statement.', statement)\n",
    "    new.append(response)\n",
    "\n",
    "with open('data-sft/general_bad_strong.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')\n",
    "\n",
    "random.shuffle(questions)\n",
    "create_jsonl(questions, new, 'general_bad_strong.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17feafd-6515-4570-bc31-1c3ace4bb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"cheating is kind of bad\"\n",
    "new = []\n",
    "\n",
    "for statement in original:\n",
    "\n",
    "    response = await convert('Make this statement much milder and kinder, using the same general form. Only output the statement.', statement)\n",
    "    new.append(response)\n",
    "\n",
    "with open('data-sft/general_bad_weak.txt', 'w') as f:\n",
    "    for statement in new:\n",
    "        f.write(statement + '\\n')\n",
    "\n",
    "random.shuffle(questions)\n",
    "create_jsonl(questions, new, 'general_bad_weak.jsonl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
